{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pandas as pa\n",
    "import statistics\n",
    "import threading\n",
    "import _thread\n",
    "import numpy as np\n",
    "import zipfile\n",
    "#from RankSum.analysis import brute_force as b\n",
    "from scipy import stats \n",
    "import ipykernel\n",
    "#from IPython.kernel import client\n",
    "\n",
    "from ipyparallel import *\n",
    "#import subgroup_analysis.brute_force as b\n",
    "\n",
    "\n",
    "#data load\n",
    "testing_data = pandas.read_csv(\"dataset/Data.csv\")\n",
    "training_data = pandas.read_csv(\"dataset/Training_Data.csv\")\n",
    "training_truth = pandas.read_csv(\"dataset/Training_Data_truth.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_t \n",
      "Rule            mean_in         ratio           P_val           p_val_out       people         \n",
      "(x14, 0)        -0.65292        -679.33489      0.01544         0.93473         129.00000      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def caculation(data):\n",
    "    trt_1 = data[data['trt'] == 1]\n",
    "    trt_0 = data[data['trt'] == 0]\n",
    "    \n",
    "    medi = statistics.median(trt_1['y']) - statistics.median(trt_0['y'])\n",
    "    mean = statistics.mean(trt_1['y']) - statistics.mean(trt_0['y'])\n",
    "    peop = len(trt_1) + len(trt_0)\n",
    "    vari = statistics.variance(trt_1['y']) + statistics.variance(trt_0['y'])\n",
    "    z_stat, p_val = stats.ranksums(trt_0['y'], trt_1['y']) \n",
    "    return [medi, mean, peop, p_val]\n",
    "\n",
    "def dataset_2():\n",
    "    \n",
    "    print('dataset_{}\\n{:<15s} {:<15s} {:<15s} {:<15s} {:<15s}'.format(\"2\",\"Rule\", \"Median\", \"Mean\", \"#ofpeople\", \"P_val\"))\n",
    "    \n",
    "    rang = ((51.1,), (51.2,), (51.3,), (51.4,), (52,), (55,), (60,))\n",
    "    data = training_data[training_data['dataset'] == 2]\n",
    "\n",
    "    for a in rang:\n",
    "        data_in = data[data['x29']< a[0]]\n",
    "        data_out = data[data['x29']>= a[0]]\n",
    "\n",
    "        w(data_in, data_out, a)\n",
    "        \n",
    "    print('\\n')\n",
    "       \n",
    "    \n",
    "def dataset_3():\n",
    "    \n",
    "    print('dataset_{}\\n{:<15s} {:<15s} {:<15s} {:<15s} {:<15s}'.format(\"3\",\"Rule\", \"Median\", \"Mean\", \"#ofpeople\", \"P_val\"))\n",
    "    \n",
    "    rang = [(1, 2), (0, 2), (0, 1)]\n",
    "    data = training_data[training_data['dataset'] == 3]\n",
    "    for a in rang:\n",
    "        data_in = data[((data['x5'] == a[0]) | (data['x5'] == a[1]))]\n",
    "        data_out = data[((data['x5'] != a[0]) & (data['x5'] != a[1]))]\n",
    "        \n",
    "        w(data_in, data_out, a)\n",
    "    print('\\n')\n",
    "\n",
    "def dataset_4():\n",
    "    \n",
    "    #print('dataset_{}\\n{:<20s} {:<20s} {:<20s} {:<20s} {:<20s} {:<20s}'.format(\"4\",\"Rule\", \"Median\", \"Mean\", \"#ofpeople\", \"P_val\", \"P_val_o\"))\n",
    "    print('dataset_{} {:<20s} {:<20s} {:<20s} {:<20s} {:<20s} {:<20s}'.format(\"4\",\"Rule\", \"Mean\", \"Mean_in\",\"Mean_out\", \"people_in\", \"P_val\", \"P_val_o\"))\n",
    "    \n",
    "    rang = [(1, 2, 55), (1, 2, 57.7), (1, 2, 58), (1, 2, 60)]\n",
    "    data = training_data[training_data['dataset'] == 4]\n",
    "    for a in rang:\n",
    "        subgroup = data[((data['x4'] == a[0]) | (data['x4'] == a[1])) & (data['x22'] > a[2])]\n",
    "        notsubgroup = data[((data['x4'] != a[0]) & (data['x4'] != a[1])) | (data['x22'] <= a[2])]\n",
    "       \n",
    "        w(data_in, data_out, a)\n",
    "        print('\\n')\n",
    "   \n",
    "    \n",
    "def te():\n",
    "    \n",
    "    print('dataset_{} \\n{:<15s} {:<15s} {:<15s} {:<15s} {:<15s} {:<15s}'.format(\"t\",\"Rule\", \"mean_in\", \"ratio\", \"P_val\", \"p_val_out\", \"people\"))\n",
    "        \n",
    "\n",
    "    d = training_data[training_data['dataset'] == 2]\n",
    "    subgroup = d[(d['x29']  < 51.3)]\n",
    "    nsg= d[(d['x29'] >= 51.3 ) ]\n",
    "     \n",
    "    a = w(subgroup, nsg, ('x14', 0))\n",
    "    \n",
    "    #print(str(a) +' ' + str(b) + ' '+ str(a*b))\n",
    "    print('\\n')\n",
    "\n",
    "def w(data_in, data_out, i):\n",
    "\n",
    "    [median_in, mean_in, people_in, p_val_in] = caculation(data_in) #selection rules\n",
    "    [median_out, mean_out, people_out, p_val_out] = caculation(data_out)\n",
    "    \n",
    "    #output\n",
    "    median = median_in / median_out\n",
    "    ratio = mean_in / mean_out\n",
    "    minus = mean_in - mean_out\n",
    "    people = people_in\n",
    "    p_val = p_val_in \n",
    "    if type(i) != tuple:\n",
    "        i = tuple(i)\n",
    "    rule ='(' + str(i[0])\n",
    "    for pos in range(1, len(i)):\n",
    "        rule = rule + ', ' + str(i[pos])\n",
    "    rule = rule + ')'\n",
    "\n",
    "    print('{:<15s} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}'.format(rule, mean_in, ratio, p_val, p_val_out, people ))\n",
    "    \n",
    "    return ratio\n",
    "     \n",
    "#dataset_2()\n",
    "#dataset_3()\n",
    "#dataset_4()\n",
    "te()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make random \n",
    "f = open('output/rands.csv', 'w')\n",
    "f.write(\"id\")\n",
    "for i in range(1,1200):\n",
    "    f.write(\",dataset_\" + str(i))\n",
    "f.write(\"\\n\")\n",
    "for i in range(1, 241):\n",
    "    f.write(str(i))\n",
    "    for j in range(1, 1200):\n",
    "        f.write(\",\" + str(random.randint(0,1)))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#make all ones\n",
    "f = open('output/one.csv', 'w')\n",
    "f.write(\"id\")\n",
    "for i in range(1,1200):\n",
    "    f.write(\",dataset_\" + str(i))\n",
    "f.write(\"\\n\")\n",
    "for i in range(1, 241):\n",
    "    f.write(str(i))\n",
    "    for j in range(1, 1200):\n",
    "        f.write(\",1\")\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing time: 3.022982120513916\n",
      "\n",
      "thread_850: 850\n",
      "thread_720: 720\n",
      "thread_1100: 1100\n",
      "thread_960: 960\n",
      "thread_850: 851\n",
      "thread_720: 721\n",
      "thread_1100: 1101\n",
      "thread_960: 961\n",
      "thread_850: 852\n",
      "thread_720: 722\n",
      "thread_1100: 1102\n",
      "thread_960: 962\n",
      "thread_720: 723\n",
      "thread_850: 853\n",
      "thread_960: 963\n",
      "thread_1100: 1103\n",
      "thread_720: 724\n",
      "thread_850: 854\n",
      "thread_960: 964\n",
      "thread_1100: 1104\n",
      "thread_720: 725\n",
      "thread_850: 855\n",
      "thread_960: 965\n",
      "thread_1100: 1105\n",
      "thread_720: 726\n",
      "thread_850: 856\n",
      "thread_960: 966\n",
      "thread_1100: 1106\n",
      "thread_720: 727\n",
      "thread_850: 857\n",
      "thread_960: 967\n",
      "thread_1100: 1107\n",
      "thread_720: 728\n",
      "thread_850: 858\n",
      "thread_960: 968\n",
      "thread_1100: 1108\n",
      "thread_720: 729\n",
      "thread_850: 859\n",
      "thread_960: 969\n",
      "thread_1100: 1109\n",
      "thread_720: 730\n",
      "thread_850: 860\n",
      "thread_960: 970\n",
      "thread_1100: 1110\n",
      "thread_720: 731\n",
      "thread_850: 861\n",
      "thread_960: 971\n",
      "thread_1100: 1111\n",
      "thread_720: 732\n",
      "thread_850: 862\n",
      "thread_960: 972\n",
      "thread_1100: 1112\n",
      "thread_720: 733\n",
      "thread_850: 863\n",
      "thread_960: 973\n",
      "thread_1100: 1113\n",
      "thread_720: 734\n",
      "thread_850: 864\n",
      "thread_960: 974\n",
      "thread_1100: 1114\n",
      "thread_720: 735\n",
      "thread_850: 865\n",
      "thread_960: 975\n",
      "thread_1100: 1115\n",
      "thread_720: 736\n",
      "thread_850: 866\n",
      "thread_960: 976\n",
      "thread_1100: 1116\n",
      "thread_850: 867\n",
      "thread_720: 737\n",
      "thread_960: 977\n",
      "thread_1100: 1117\n",
      "thread_850: 868\n",
      "thread_720: 738\n",
      "thread_960: 978\n",
      "thread_1100: 1118\n",
      "thread_850: 869\n",
      "thread_720: 739\n",
      "thread_960: 979\n",
      "thread_1100: 1119\n",
      "thread_850: 870\n",
      "thread_720: 740\n",
      "thread_960: 980\n",
      "thread_1100: 1120\n",
      "thread_850: 871\n",
      "thread_720: 741\n",
      "thread_960: 981\n",
      "thread_1100: 1121\n",
      "thread_850: 872\n",
      "thread_720: 742\n",
      "thread_960: 982\n",
      "thread_1100: 1122\n",
      "thread_720: 743\n",
      "thread_850: 873\n",
      "thread_960: 983\n",
      "thread_1100: 1123\n",
      "thread_720: 744\n",
      "thread_850: 874\n",
      "thread_960: 984\n",
      "thread_1100: 1124\n",
      "thread_850: 875\n",
      "thread_720: 745\n",
      "thread_960: 985\n",
      "thread_1100: 1125\n",
      "thread_850: 876\n",
      "thread_720: 746\n",
      "thread_960: 986\n",
      "thread_1100: 1126\n",
      "thread_850: 877\n",
      "thread_720: 747\n",
      "thread_960: 987\n",
      "thread_1100: 1127\n",
      "thread_850: 878\n",
      "thread_720: 748\n",
      "thread_960: 988\n",
      "thread_1100: 1128\n",
      "thread_850: 879\n",
      "thread_720: 749\n",
      "thread_960: 989\n",
      "thread_1100: 1129\n",
      "thread_850: 880\n",
      "thread_720: 750\n",
      "thread_960: 990\n",
      "thread_1100: 1130\n",
      "thread_850: 881\n",
      "thread_720: 751\n",
      "thread_960: 991\n",
      "thread_1100: 1131\n",
      "thread_720: 752\n",
      "thread_850: 882\n",
      "thread_960: 992\n",
      "thread_1100: 1132\n",
      "thread_850: 883\n",
      "thread_720: 753\n",
      "thread_960: 993\n",
      "thread_1100: 1133\n",
      "thread_850: 884\n",
      "thread_720: 754\n",
      "thread_960: 994\n",
      "thread_1100: 1134\n",
      "thread_850: 885\n",
      "thread_720: 755\n",
      "thread_960: 995\n",
      "thread_1100: 1135\n",
      "thread_850: 886\n",
      "thread_720: 756\n",
      "thread_960: 996\n",
      "thread_1100: 1136\n",
      "thread_850: 887\n",
      "thread_720: 757\n",
      "thread_960: 997\n",
      "thread_1100: 1137\n",
      "thread_850: 888\n",
      "thread_720: 758\n",
      "thread_960: 998\n",
      "thread_1100: 1138\n",
      "thread_850: 889\n",
      "thread_720: 759\n",
      "thread_960: 999\n",
      "thread_1100: 1139\n",
      "thread_850: 890\n",
      "thread_720: 760\n",
      "thread_960: 1000\n",
      "thread_1100: 1140\n",
      "thread_850: 891\n",
      "thread_720: 761\n",
      "thread_960: 1001\n",
      "thread_1100: 1141\n",
      "thread_850: 892\n",
      "thread_960: 1002\n",
      "thread_720: 762\n",
      "thread_1100: 1142\n",
      "thread_850: 893\n",
      "thread_960: 1003\n",
      "thread_720: 763\n",
      "thread_1100: 1143\n",
      "thread_850: 894\n",
      "thread_960: 1004\n",
      "thread_720: 764\n",
      "thread_1100: 1144\n",
      "thread_850: 895\n",
      "thread_960: 1005\n",
      "thread_720: 765\n",
      "thread_1100: 1145\n",
      "thread_850: 896\n",
      "thread_720: 766\n",
      "thread_960: 1006\n",
      "thread_1100: 1146\n",
      "thread_850: 897\n",
      "thread_720: 767\n",
      "thread_960: 1007\n",
      "thread_1100: 1147\n",
      "thread_850: 898\n",
      "thread_720: 768\n",
      "thread_960: 1008\n",
      "thread_1100: 1148\n",
      "thread_850: 899\n",
      "thread_720: 769\n",
      "thread_960: 1009\n",
      "thread_1100: 1149\n",
      "thread_850: 900\n",
      "thread_720: 770\n",
      "thread_960: 1010\n",
      "thread_1100: 1150\n",
      "thread_850: 901\n",
      "thread_960: 1011\n",
      "thread_720: 771\n",
      "thread_1100: 1151\n",
      "thread_850: 902\n",
      "thread_960: 1012\n",
      "thread_720: 772\n",
      "thread_1100: 1152\n",
      "thread_960: 1013\n",
      "thread_720: 773\n",
      "thread_850: 903\n",
      "thread_1100: 1153\n",
      "thread_960: 1014\n",
      "thread_720: 774\n",
      "thread_850: 904\n",
      "thread_1100: 1154\n",
      "thread_960: 1015\n",
      "thread_720: 775\n",
      "thread_850: 905\n",
      "thread_1100: 1155\n",
      "thread_960: 1016\n",
      "thread_720: 776\n",
      "thread_850: 906\n",
      "thread_1100: 1156\n",
      "thread_960: 1017\n",
      "thread_720: 777\n",
      "thread_850: 907\n",
      "thread_1100: 1157\n",
      "thread_960: 1018\n",
      "thread_720: 778\n",
      "thread_850: 908\n",
      "thread_1100: 1158\n",
      "thread_960: 1019\n",
      "thread_850: 909\n",
      "thread_720: 779\n",
      "thread_1100: 1159\n",
      "thread_850: 910\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import threading\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "def Threadfun(sleeptime, start, end):\n",
    "    s = \"\"\n",
    "    for i in range(start, end): #of dataset\n",
    "        tw = testData[testData['dataset'] == i]\n",
    "        for j in range(0, 240): #of id\n",
    "            s = s + \"0\"\n",
    "            for k in range(1, 43):    #of feature\n",
    "                s = s + \" \" + str(k) + \":\" + str(tw.loc[240*(i-1) + j][k+1])\n",
    "            s = s + \"\\n\"\n",
    "        time.sleep(sleeptime)\n",
    "        print('thread_{0}: {1}'.format(start, i))\n",
    "    file = open(('dataset/svmtest_{0}'.format(start)), 'w')\n",
    "\n",
    "    file.write(s)\n",
    "    file.close \n",
    "\n",
    "def main():\n",
    "\n",
    "    # _thread.start_new_thread(Threadfun, (0.1, 1, 241))\n",
    "    # _thread.start_new_thread(Threadfun, (0.1, 600, 720))\n",
    "    _thread.start_new_thread(Threadfun, (0.1, 720, 850))\n",
    "    _thread.start_new_thread(Threadfun, (0.3, 850, 960))\n",
    "    _thread.start_new_thread(Threadfun, (0.5, 960, 1100))\n",
    "    _thread.start_new_thread(Threadfun, (0.7, 1100, 1201))\n",
    "\n",
    "#test file    \n",
    "\n",
    "testData = testing_data.copy()\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "P_VALUE_THRESHOLD = 0.05\n",
    "TRT_EFFECT_THRESHOLD = -0.6\n",
    "NUMBER_THRESHOLD = [50, 150]\n",
    "\n",
    "'''\n",
    "g+_effect_size=  Differance of trt_effect in Subgroup/ Standard deviation of Subgroup\n",
    "g+_power= n/s\n",
    "g+_total_n= Subgroup的總人數\n",
    "\n",
    "g+_trt_effect= “g+_1_mean”─”g+_0-mean”\n",
    "g+_P-value= P-value of “g+_trt_effect”\n",
    "g+_1_mean= “g+_1_mean”\n",
    "g+_1_n=  Subgroup內新治療的總人數\n",
    "g+_0_mean= “g+_0_mean”\n",
    "\n",
    "g-_trt_effect= “g-_1_mean”─”g-_0-mean” \n",
    "g-_P-value= P-value of “g-_trt_effect”\n",
    "g-_1_mean= “g-_1_mean” \n",
    "g-_1_n= Subgroup內舊治療的總人數 \n",
    "g-_0_mean= “g-_0_mean”\n",
    "\n",
    "trt_effect_1= “g+_1_mean”─”g-_1-mean”\n",
    "P-value_1= P-value of “1_trt_effect”\n",
    "trt_effect_1= “g+_0_mean”─”g-_0-mean”\n",
    "P-value_1= P-value of “0_trt_effect”\n",
    "'''\n",
    "\n",
    "def evaluation(d):  \n",
    "    # Subgroup\n",
    "    gp = d[d['group'] == 1]\n",
    "    gp_1 = gp[gp['trt'] == 1]\n",
    "    gp_0 = gp[gp['trt'] == 0]\n",
    "\n",
    "    gp_1_num = len(gp_1)\n",
    "    gp_0_num = len(gp_0)\n",
    "    gp_num = gp_1_num + gp_0_num\n",
    "    \n",
    "    if gp_1_num < 2 or gp_0_num < 2:\n",
    "        return None\n",
    "\n",
    "    gp_trt_effect = statistics.mean(gp_1['y']) - statistics.mean(gp_0['y'])\n",
    "\n",
    "    gp_1_stdev = statistics.stdev(gp_1['y'])\n",
    "    gp_0_stdev = statistics.stdev(gp_0['y'])\n",
    "    tmp_1 = (gp_1_num-1)*math.pow(gp_1_stdev, 2)\n",
    "    tmp_0 = (gp_0_num-1)*math.pow(gp_0_stdev, 2)\n",
    "    gp_stdev = math.sqrt((tmp_1 + tmp_0)/(gp_1_num + gp_0_num - 2))\n",
    "\n",
    "    gp_ratio = gp_0_num / gp_1_num\n",
    "    _, gp_p = stats.ttest_ind(gp_1['y'], gp_0['y'], equal_var=False)\n",
    "    gp_p /= 2\n",
    "\n",
    "    gp_effect_size = gp_trt_effect/gp_stdev\n",
    "    # power = TTestIndPower.power(-effect_size, new_trt_number, P_VALUE_THRESHOLD, ratio, new_trt_number+old_trt_number-2, alternative=\"larger\")\n",
    "\n",
    "    # Nongroup\n",
    "    gn = d[d['group'] == 0]\n",
    "    gn_1 = gn[gn['trt'] == 1]\n",
    "    gn_0 = gn[gn['trt'] == 0]\n",
    "\n",
    "    gn_1_num = len(gn_1)\n",
    "    gn_0_num = len(gn_0)\n",
    "    gn_num = gn_1_num + gn_0_num\n",
    "    if gn_1_num < 2 or gn_0_num < 2:\n",
    "        return None\n",
    "\n",
    "    gn_trt_effect = statistics.mean(gn_1['y']) - statistics.mean(gn_0['y'])\n",
    "\n",
    "    gn_1_stdev = statistics.stdev(gn_1['y'])\n",
    "    gn_0_stdev = statistics.stdev(gn_0['y'])\n",
    "    tmp_1 = (gn_1_num-1)*math.pow(gn_1_stdev, 2)\n",
    "    tmp_0 = (gn_0_num-1)*math.pow(gn_0_stdev, 2)\n",
    "    gn_stdev = math.sqrt((tmp_1 + tmp_0)/(gn_1_num + gn_0_num - 2))\n",
    "\n",
    "    gn_effect_size = gn_trt_effect/gn_stdev\n",
    "\n",
    "    _, gn_p = stats.ttest_ind(gn_1['y'], gn_0['y'], equal_var=False)\n",
    "    gn_p /= 2\n",
    "\n",
    "    # Inter\n",
    "    trt_effect_1 = statistics.mean(gp_1['y']) - statistics.mean(gn_1['y'])\n",
    "    trt_effect_0 = statistics.mean(gp_0['y']) - statistics.mean(gn_0['y'])\n",
    "\n",
    "    _, p_1 = stats.ttest_ind(gp_1['y'], gn_1['y'], equal_var=False)\n",
    "    _, p_0 = stats.ttest_ind(gp_0['y'], gn_0['y'], equal_var=False)\n",
    "\n",
    "    \n",
    "    # Filter\n",
    "    if gp_trt_effect > TRT_EFFECT_THRESHOLD:\n",
    "        return None\n",
    "    elif trt_effect_1 > TRT_EFFECT_THRESHOLD:\n",
    "        return None\n",
    "    elif gp_p > P_VALUE_THRESHOLD:\n",
    "        return None\n",
    "    elif p_1 > P_VALUE_THRESHOLD:\n",
    "        return None\n",
    "    elif gp_num < NUMBER_THRESHOLD[0] or gp_num > NUMBER_THRESHOLD[1]:\n",
    "        return None\n",
    "\n",
    "    gp_1_mean = statistics.mean(gp_1['y'])\n",
    "    gp_0_mean = statistics.mean(gp_0['y'])\n",
    "    gn_1_mean = statistics.mean(gn_1['y'])\n",
    "    gn_0_mean = statistics.mean(gn_0['y'])\n",
    "    return gp_effect_size, gp_num, gp_trt_effect, gp_p, gp_1_mean, gp_1_num, gp_0_mean, gn_trt_effect, gn_p, gn_1_mean, gn_1_num, gn_0_mean,trt_effect_1, p_1, trt_effect_0, p_0\n",
    "\n",
    "def update_topN(score, rule, topN_score, case):\n",
    "    if score == 0:    #why??\n",
    "        return topN_score\n",
    "    \n",
    "    if case == 1:     # 1 = abs higher would be better\n",
    "        s = abs(score)\n",
    "    elif case == 2:   # 2 = close to 100 would be better\n",
    "        s = abs(score - 100)\n",
    "    else:             \n",
    "        s = score\n",
    "    topN_score.sort()  \n",
    "    \n",
    "    if len(topN_score)>=10 :\n",
    "        \n",
    "        key = []\n",
    "        if (case == 1 | case == 4):    #higher would be better\n",
    "            if s > topN_score[0][0]:    \n",
    "                key = topN_score[0]\n",
    "           \n",
    "        else:       \n",
    "            topN_score.reverse()    #lower score would be better\n",
    "            if s < topN_score[0][0]:\n",
    "                key = topN_score[0]\n",
    "        \n",
    "        if key in topN_score:\n",
    "            topN_score.remove(key)\n",
    "        else:\n",
    "            return topN_score\n",
    "        \n",
    "    topN_score.append([s, score, rule])\n",
    "    \n",
    "    return topN_score\n",
    "    \n",
    "\n",
    "# Grouping method\n",
    "def check_group(patient, rule):\n",
    "    index, values, tag = rule\n",
    "    if tag == '=':\n",
    "        for v in values:\n",
    "            if patient[index+3] == v:\n",
    "                return 1\n",
    "        return 0\n",
    "    elif tag == '>':\n",
    "        if patient[index+3] > values[0]:\n",
    "            return 1\n",
    "    else:\n",
    "        if patient[index+3] < values[0]:\n",
    "            return 1\n",
    "    return 0\n",
    "   \n",
    "\n",
    "def quartile(d):\n",
    "    Q1 = np.percentile(d, 25)\n",
    "    Q2 = np.percentile(d, 50)\n",
    "    Q3 = np.percentile(d, 75)\n",
    "    return [(Q1), (Q2), (Q3)]\n",
    "\n",
    "\n",
    "def possible_rules(d):\n",
    "    con_items = range(1, 21)\n",
    "    dis_items = range(21, 41)\n",
    "    dis_value =[[0], [1], [2], [0, 1], [0, 2], [1, 2]]\n",
    "    rules = []\n",
    "\n",
    "    for item in con_items:\n",
    "        for value in dis_value:\n",
    "            rules.append([(item), value, '='])\n",
    "            \n",
    "    for item in dis_items:\n",
    "        con_values = quartile(d['x'+str(item)])\n",
    "        for value in con_values:\n",
    "            rules.append([(item), [value], '>'])\n",
    "            rules.append([(item), [value], '<'])\n",
    "    return rules  \n",
    "\n",
    "            \n",
    "def return_key(item):\n",
    "    if item[2] == '=':\n",
    "        key = 'x{} {} {}'.format((item[0]), item[2], item[1])\n",
    "            \n",
    "    else:\n",
    "        key = 'x{} {} {:.3f}'.format((item[0]), item[2], item[1][0])\n",
    "    return key\n",
    "\n",
    "def rank_sum(dic, topN_score):\n",
    "    topN_score.reverse()\n",
    "    for i in range(0, len(topN_score)):\n",
    "        key = topN_score[i]\n",
    "\n",
    "        if key in dic:\n",
    "            dic[key] = dic[key] + (i+1)\n",
    "        else:\n",
    "            dic[key] = (i+1)\n",
    "    return dic\n",
    "\n",
    "def print_all(save_all):\n",
    "    print('rule \\t\\t ratio \\t   minus    trt_effec  nongroup_mean   number      p_val  non_p_val')\n",
    "    for i in save_all:\n",
    "        ratio, minus, trt_effect,nongroup_mean, number, p_val, non_p_val = i[1]\n",
    "        print('{:12s}: {:10.3f} {:10.3f}  {:10.3f} {:10.3f} {:10.3f} {:10.3f} {:10.3f}'.format(return_key(i[0]), ratio, minus, trt_effect,nongroup_mean, number, p_val, non_p_val))\n",
    "\n",
    "def write(topN_score):\n",
    "    for item in topN_score:\n",
    "        key = return_key(item[2])\n",
    "        print('{} : {:.5f}'.format(key, item[1]))\n",
    "        \n",
    "def sss(all_score, attribute, ascend):\n",
    "    count = 10\n",
    "    topN = all_score.sort_values(by = attribute, ascending = ascend).head(10)\n",
    "    for i in topN.index:\n",
    "        all_score.loc[i, 'score'] = all_score.loc[i, 'score'] + count\n",
    "        count = count-1\n",
    "    return all_score\n",
    "\n",
    "def make_upload_file(start_dataset, end_dataset, all_rules, df, ans):\n",
    "    \n",
    "    if 'group' not in df:\n",
    "        df['group'] = 0\n",
    "        \n",
    "    for did in range(start_dataset, end_dataset+1):\n",
    "        #initial\n",
    "        ans['dataset_{}'.format(did)] = 0\n",
    "        d = df[df['dataset'] == did].copy()\n",
    "        rule = all_rules[did%150 - 1]\n",
    "        if type(rule) == int:\n",
    "            print('r: ',rule)\n",
    "            continue\n",
    "\n",
    "        for i in range(1, 241):\n",
    "            patient = d[d['id'] == i].iloc[0] \n",
    "            g = check_group(patient, rule)\n",
    "            d.loc[d['id'] == i, 'group'] = g\n",
    "            \n",
    "        subgroup = d[d['group'] == 1]\n",
    "        for i in subgroup['id']:\n",
    "            ans.loc[i-1, 'dataset_{}'.format(did)] = 1\n",
    "     \n",
    "    #zf = zipfile.ZipFile('result_{}.zip'.format(name), 'w', zipfile.ZIP_DEFLATED)\n",
    "    #zf.write('result_{}.csv'.format(name))\n",
    "    return ans        \n",
    "    \n",
    "def analysis(t):\n",
    "    result = []\n",
    "    df, start_dataset, end_dataset, rule_len = t\n",
    "    idx = ['rule', 'gp_effect_size', 'gp_num', 'gp_trt_effect', 'gp_p', 'gp_1_mean', 'gp_1_num', 'gp_0_mean', 'gn_trt_effect', 'gn_p', 'gn_1_mean', 'gn_1_num', 'gn_0_mean', 'trt_effect_1', 'p_1', 'trt_effect_0', 'p_0']\n",
    "        \n",
    "    # Set default group number to every patients\n",
    "    if 'group' not in df:\n",
    "        df['group'] = 0\n",
    "    \n",
    "       \n",
    "    for did in range(start_dataset, end_dataset+1):\n",
    "        \n",
    "        #initial\n",
    "        all_score = pandas.DataFrame([], columns=(idx))\n",
    "        save_all = []\n",
    "        \n",
    "        print('Dataset {}'.format(did))\n",
    "        d = df[df['dataset'] == did].copy()\n",
    "        \n",
    "        for rule in possible_rules(d):\n",
    "            d = df[df['dataset'] == did].copy()\n",
    "            for i in range(1, 241):\n",
    "                patient = d[d['id'] == i].iloc[0] \n",
    "                g = check_group(patient, rule)\n",
    "                d.loc[d['id'] == i, 'group'] = g\n",
    "            \n",
    "            # Evaluate the treatment effect according each rule\n",
    "            parts = evaluation(d)\n",
    "            if parts == None:\n",
    "                continue\n",
    "\n",
    "            # Caculate the socre\n",
    "            gp_effect_size, gp_num, gp_trt_effect, gp_p, gp_1_mean, gp_1_num, gp_0_mean, gn_trt_effect, gn_p, gn_1_mean, gn_1_num, gn_0_mean,trt_effect_1, p_1, trt_effect_0, p_0 = parts\n",
    "            save_all.append([rule, gp_effect_size, gp_num, gp_trt_effect, gp_p, gp_1_mean, gp_1_num, gp_0_mean, gn_trt_effect, gn_p, gn_1_mean, gn_1_num, gn_0_mean,trt_effect_1, p_1, trt_effect_0, p_0])\n",
    "\n",
    "        for i in range(0, len(save_all)):\n",
    "            all_score.loc[i] = save_all[i] \n",
    "        all_score.to_pickle('pickle/Dataset_training6{}_score.p'.format(did))\n",
    "        all_score.to_csv('csv/Dataset_training6{}_score.csv'.format(did))\n",
    "        \n",
    "        #topN_Ratio = sss(all_score, 'abs(ratio)', False )\n",
    "        #all_score = sss(all_score, 'minus', True )\n",
    "        #all_score = sss(all_score, 'trt_effect', True )\n",
    "        #all_score = sss(all_score, 'nongroup_trt_effect', False )\n",
    " \n",
    "        #top = all_score.sort_values(by = 'score', ascending = False).head(1)\n",
    "        #if len(top['rule']) < 1:\n",
    "        #    result.append([0, [0], 0])\n",
    "        #else:    \n",
    "        #    result.append(top['rule'].values[0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2\n",
      "\n",
      "--- 116.36772084236145 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = (training_data, 2, 2, 1)\n",
    "start_time = time.time()\n",
    "s_all = analysis(params)\n",
    "print(\"\\n--- {} seconds ---\\n\".format(time.time() - start_time))\n",
    "#跑一個dataset大概104s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Dataset 151\n",
      "Dataset 301\n",
      "Dataset 451\n",
      "Dataset 601\n",
      "Dataset 751\n",
      "Dataset 901\n",
      "Dataset 1051\n",
      "Dataset 2\n",
      "Dataset 152\n",
      "Dataset 302\n",
      "Dataset 452\n",
      "Dataset 602\n",
      "Dataset 752\n",
      "Dataset 902\n",
      "Dataset 1052\n",
      "Dataset 3\n",
      "Dataset 153\n",
      "Dataset 303\n",
      "Dataset 453\n",
      "Dataset 603\n",
      "Dataset 753\n",
      "Dataset 903\n",
      "Dataset 1053\n",
      "Dataset 4\n",
      "Dataset 154\n",
      "Dataset 304\n",
      "Dataset 454\n",
      "Dataset 604\n",
      "Dataset 754\n",
      "Dataset 904\n",
      "Dataset 1054\n",
      "Dataset 5\n",
      "Dataset 155\n",
      "Dataset 305\n",
      "Dataset 455\n",
      "Dataset 605\n",
      "Dataset 755\n",
      "Dataset 905\n",
      "Dataset 1055\n",
      "Dataset 6\n",
      "Dataset 156\n",
      "Dataset 306\n",
      "Dataset 456\n",
      "Dataset 606\n",
      "Dataset 756\n",
      "Dataset 906\n",
      "Dataset 1056\n",
      "Dataset 157\n",
      "Dataset 7\n",
      "Dataset 307\n",
      "Dataset 457\n",
      "Dataset 607\n",
      "Dataset 757\n",
      "Dataset 907\n",
      "Dataset 1057\n",
      "Dataset 158\n",
      "Dataset 8\n",
      "Dataset 458\n",
      "Dataset 308\n",
      "Dataset 608\n",
      "Dataset 758\n",
      "Dataset 908\n",
      "Dataset 1058\n",
      "Dataset 159\n",
      "Dataset 9\n",
      "Dataset 459\n",
      "Dataset 309\n",
      "Dataset 609\n",
      "Dataset 759\n",
      "Dataset 909\n",
      "Dataset 1059\n",
      "Dataset 160\n",
      "Dataset 10\n",
      "Dataset 460\n",
      "Dataset 310\n",
      "Dataset 610\n",
      "Dataset 760\n",
      "Dataset 910\n",
      "Dataset 1060\n",
      "Dataset 161\n",
      "Dataset 11\n",
      "Dataset 461\n",
      "Dataset 311\n",
      "Dataset 611\n",
      "Dataset 761\n",
      "Dataset 911\n",
      "Dataset 1061\n",
      "Dataset 162\n",
      "Dataset 12\n",
      "Dataset 462\n",
      "Dataset 312\n",
      "Dataset 612\n",
      "Dataset 762\n",
      "Dataset 912\n",
      "Dataset 1062\n",
      "Dataset 163\n",
      "Dataset 13\n",
      "Dataset 463\n",
      "Dataset 313\n",
      "Dataset 613\n",
      "Dataset 763\n",
      "Dataset 913\n",
      "Dataset 1063\n",
      "Dataset 164\n",
      "Dataset 14\n",
      "Dataset 464\n",
      "Dataset 314\n",
      "Dataset 614\n",
      "Dataset 764\n",
      "Dataset 914\n",
      "Dataset 1064\n",
      "Dataset 165\n",
      "Dataset 15\n",
      "Dataset 465\n",
      "Dataset 315\n",
      "Dataset 615\n",
      "Dataset 765\n",
      "Dataset 915\n",
      "Dataset 1065\n",
      "Dataset 166\n",
      "Dataset 16\n",
      "Dataset 466\n",
      "Dataset 316\n",
      "Dataset 616\n",
      "Dataset 766\n",
      "Dataset 916\n",
      "Dataset 1066\n",
      "Dataset 167\n",
      "Dataset 17\n",
      "Dataset 467\n",
      "Dataset 317\n",
      "Dataset 617\n",
      "Dataset 767\n",
      "Dataset 917\n",
      "Dataset 1067\n",
      "Dataset 168\n",
      "Dataset 18\n",
      "Dataset 468\n",
      "Dataset 318\n",
      "Dataset 618\n",
      "Dataset 768\n",
      "Dataset 918\n",
      "Dataset 1068\n",
      "Dataset 169\n",
      "Dataset 19\n",
      "Dataset 469\n",
      "Dataset 619\n",
      "Dataset 319\n",
      "Dataset 769\n",
      "Dataset 919\n",
      "Dataset 1069\n",
      "Dataset 170\n",
      "Dataset 20\n",
      "Dataset 470\n",
      "Dataset 620\n",
      "Dataset 320\n",
      "Dataset 770\n",
      "Dataset 920\n",
      "Dataset 1070\n",
      "Dataset 171\n",
      "Dataset 21\n",
      "Dataset 471\n",
      "Dataset 621\n",
      "Dataset 321\n",
      "Dataset 771\n",
      "Dataset 921\n",
      "Dataset 1071\n",
      "Dataset 172\n",
      "Dataset 22\n",
      "Dataset 472\n",
      "Dataset 322\n",
      "Dataset 622\n",
      "Dataset 772\n",
      "Dataset 922\n",
      "Dataset 1072\n",
      "Dataset 173\n",
      "Dataset 23\n",
      "Dataset 473\n",
      "Dataset 323\n",
      "Dataset 623\n",
      "Dataset 773\n",
      "Dataset 923\n",
      "Dataset 1073\n",
      "Dataset 174\n",
      "Dataset 24\n",
      "Dataset 474\n",
      "Dataset 324\n",
      "Dataset 624\n",
      "Dataset 774\n",
      "Dataset 924\n",
      "Dataset 1074\n",
      "Dataset 175\n",
      "Dataset 25\n",
      "Dataset 475\n",
      "Dataset 325\n",
      "Dataset 625\n",
      "Dataset 775\n",
      "Dataset 925\n",
      "Dataset 1075\n",
      "Dataset 176\n",
      "Dataset 26\n",
      "Dataset 476\n",
      "Dataset 326\n",
      "Dataset 626\n",
      "Dataset 776\n",
      "Dataset 926\n",
      "Dataset 1076\n",
      "Dataset 177\n",
      "Dataset 27\n",
      "Dataset 477\n",
      "Dataset 627\n",
      "Dataset 327\n",
      "Dataset 777\n",
      "Dataset 927\n",
      "Dataset 1077\n",
      "Dataset 178\n",
      "Dataset 28\n",
      "Dataset 478\n",
      "Dataset 328\n",
      "Dataset 628\n",
      "Dataset 778\n",
      "Dataset 928\n",
      "Dataset 1078\n",
      "Dataset 179\n",
      "Dataset 29\n",
      "Dataset 479\n",
      "Dataset 329\n",
      "Dataset 629\n",
      "Dataset 779\n",
      "Dataset 929\n",
      "Dataset 1079\n",
      "Dataset 180\n",
      "Dataset 30\n",
      "Dataset 480\n",
      "Dataset 630\n",
      "Dataset 330\n",
      "Dataset 780\n",
      "Dataset 930\n",
      "Dataset 1080\n",
      "Dataset 181\n",
      "Dataset 31\n",
      "Dataset 481\n",
      "Dataset 631\n",
      "Dataset 331\n",
      "Dataset 781\n",
      "Dataset 931\n",
      "Dataset 1081\n",
      "Dataset 182\n",
      "Dataset 32\n",
      "Dataset 482\n",
      "Dataset 632\n",
      "Dataset 332\n",
      "Dataset 782\n",
      "Dataset 932\n",
      "Dataset 1082\n",
      "Dataset 183\n",
      "Dataset 33\n",
      "Dataset 483\n",
      "Dataset 333\n",
      "Dataset 633\n",
      "Dataset 783\n",
      "Dataset 933\n",
      "Dataset 1083\n",
      "Dataset 184\n",
      "Dataset 34\n",
      "Dataset 484\n",
      "Dataset 634\n",
      "Dataset 334\n",
      "Dataset 784\n",
      "Dataset 934\n",
      "Dataset 1084\n",
      "Dataset 185\n",
      "Dataset 35\n",
      "Dataset 485\n",
      "Dataset 635\n",
      "Dataset 335\n",
      "Dataset 785\n",
      "Dataset 935\n",
      "Dataset 1085\n",
      "Dataset 186\n",
      "Dataset 36\n",
      "Dataset 486\n",
      "Dataset 636\n",
      "Dataset 336\n",
      "Dataset 786\n",
      "Dataset 936\n",
      "Dataset 1086\n",
      "Dataset 187\n",
      "Dataset 37\n",
      "Dataset 487\n",
      "Dataset 637\n",
      "Dataset 337\n",
      "Dataset 787\n",
      "Dataset 937\n",
      "Dataset 1087\n",
      "Dataset 188\n",
      "Dataset 38\n",
      "Dataset 488\n",
      "Dataset 638\n",
      "Dataset 338\n",
      "Dataset 788\n",
      "Dataset 938\n",
      "Dataset 1088\n",
      "Dataset 189\n",
      "Dataset 39\n",
      "Dataset 489\n",
      "Dataset 639\n",
      "Dataset 339\n",
      "Dataset 789\n",
      "Dataset 939\n",
      "Dataset 1089\n",
      "Dataset 190\n",
      "Dataset 40\n",
      "Dataset 490\n",
      "Dataset 640\n",
      "Dataset 340\n",
      "Dataset 790\n",
      "Dataset 940\n",
      "Dataset 1090\n",
      "Dataset 191\n",
      "Dataset 41\n",
      "Dataset 491\n",
      "Dataset 641\n",
      "Dataset 791\n",
      "Dataset 341\n",
      "Dataset 941\n",
      "Dataset 1091\n",
      "Dataset 192\n",
      "Dataset 42\n",
      "Dataset 492\n",
      "Dataset 642\n",
      "Dataset 342\n",
      "Dataset 792\n",
      "Dataset 942\n",
      "Dataset 1092\n",
      "Dataset 193\n",
      "Dataset 43\n",
      "Dataset 493\n",
      "Dataset 643\n",
      "Dataset 793\n",
      "Dataset 343\n",
      "Dataset 943\n",
      "Dataset 1093\n",
      "Dataset 194\n",
      "Dataset 44\n",
      "Dataset 494\n",
      "Dataset 644\n",
      "Dataset 794\n",
      "Dataset 344\n",
      "Dataset 944\n",
      "Dataset 1094\n",
      "Dataset 195\n",
      "Dataset 45\n",
      "Dataset 495\n",
      "Dataset 645\n",
      "Dataset 795\n",
      "Dataset 345\n",
      "Dataset 945\n",
      "Dataset 1095\n",
      "Dataset 196\n",
      "Dataset 46\n",
      "Dataset 496\n",
      "Dataset 646\n",
      "Dataset 796\n",
      "Dataset 346\n",
      "Dataset 946\n",
      "Dataset 1096\n",
      "Dataset 197\n",
      "Dataset 47\n",
      "Dataset 497\n",
      "Dataset 647\n",
      "Dataset 797\n",
      "Dataset 347\n",
      "Dataset 947\n",
      "Dataset 1097\n",
      "Dataset 198\n",
      "Dataset 48\n",
      "Dataset 498\n",
      "Dataset 648\n",
      "Dataset 798\n",
      "Dataset 348\n",
      "Dataset 948\n",
      "Dataset 1098\n",
      "Dataset 199\n",
      "Dataset 49\n",
      "Dataset 499\n",
      "Dataset 649\n",
      "Dataset 799\n",
      "Dataset 349\n",
      "Dataset 949\n",
      "Dataset 1099\n",
      "Dataset 200\n",
      "Dataset 50\n",
      "Dataset 500\n",
      "Dataset 650\n",
      "Dataset 800\n",
      "Dataset 950\n",
      "Dataset 350\n",
      "Dataset 1100\n",
      "Dataset 201\n",
      "Dataset 51\n",
      "Dataset 501\n",
      "Dataset 651\n",
      "Dataset 801\n",
      "Dataset 951\n",
      "Dataset 351\n",
      "Dataset 1101\n",
      "Dataset 202\n",
      "Dataset 52\n",
      "Dataset 502\n",
      "Dataset 652\n",
      "Dataset 802\n",
      "Dataset 952\n",
      "Dataset 352\n",
      "Dataset 1102\n",
      "Dataset 203\n",
      "Dataset 53\n",
      "Dataset 503\n",
      "Dataset 653\n",
      "Dataset 803\n",
      "Dataset 953\n",
      "Dataset 353\n",
      "Dataset 1103\n",
      "Dataset 204\n",
      "Dataset 54\n",
      "Dataset 504\n",
      "Dataset 654\n",
      "Dataset 804\n",
      "Dataset 954\n",
      "Dataset 354\n",
      "Dataset 1104\n",
      "Dataset 205\n",
      "Dataset 55\n",
      "Dataset 505\n",
      "Dataset 655\n",
      "Dataset 805\n",
      "Dataset 955\n",
      "Dataset 355\n",
      "Dataset 1105\n",
      "Dataset 206\n",
      "Dataset 56\n",
      "Dataset 506\n",
      "Dataset 656\n",
      "Dataset 806\n",
      "Dataset 956\n",
      "Dataset 356\n",
      "Dataset 1106\n",
      "Dataset 207\n",
      "Dataset 57\n",
      "Dataset 507\n",
      "Dataset 657\n",
      "Dataset 807\n",
      "Dataset 957\n",
      "Dataset 357\n",
      "Dataset 1107\n",
      "Dataset 208\n",
      "Dataset 58\n",
      "Dataset 508\n",
      "Dataset 658\n",
      "Dataset 808\n",
      "Dataset 958\n",
      "Dataset 358\n",
      "Dataset 1108\n",
      "Dataset 209\n",
      "Dataset 59\n",
      "Dataset 509\n",
      "Dataset 659\n",
      "Dataset 809\n",
      "Dataset 959\n",
      "Dataset 359\n",
      "Dataset 1109\n",
      "Dataset 210\n",
      "Dataset 60\n",
      "Dataset 510\n",
      "Dataset 660\n",
      "Dataset 810\n",
      "Dataset 960\n",
      "Dataset 360\n",
      "Dataset 1110\n",
      "Dataset 211\n",
      "Dataset 61\n",
      "Dataset 511\n",
      "Dataset 661\n",
      "Dataset 811\n",
      "Dataset 961\n",
      "Dataset 361\n",
      "Dataset 1111\n",
      "Dataset 212\n",
      "Dataset 62\n",
      "Dataset 512\n",
      "Dataset 662\n",
      "Dataset 812\n",
      "Dataset 962\n",
      "Dataset 362\n",
      "Dataset 1112\n",
      "Dataset 213\n",
      "Dataset 63\n",
      "Dataset 513\n",
      "Dataset 813\n",
      "Dataset 663\n",
      "Dataset 963\n",
      "Dataset 363\n",
      "Dataset 1113\n",
      "Dataset 214\n",
      "Dataset 64\n",
      "Dataset 514\n",
      "Dataset 814\n",
      "Dataset 664\n",
      "Dataset 964\n",
      "Dataset 364\n",
      "Dataset 1114\n",
      "Dataset 215\n",
      "Dataset 65\n",
      "Dataset 515\n",
      "Dataset 815\n",
      "Dataset 965\n",
      "Dataset 665\n",
      "Dataset 365\n",
      "Dataset 1115\n",
      "Dataset 216\n",
      "Dataset 66\n",
      "Dataset 516\n",
      "Dataset 816\n",
      "Dataset 966\n",
      "Dataset 666\n",
      "Dataset 366\n",
      "Dataset 1116\n",
      "Dataset 217\n",
      "Dataset 67\n",
      "Dataset 517\n",
      "Dataset 817\n",
      "Dataset 967\n",
      "Dataset 667\n",
      "Dataset 367\n",
      "Dataset 1117\n",
      "Dataset 218\n",
      "Dataset 68\n",
      "Dataset 518\n",
      "Dataset 818\n",
      "Dataset 968\n",
      "Dataset 668\n",
      "Dataset 368\n",
      "Dataset 1118\n",
      "Dataset 219\n",
      "Dataset 69\n",
      "Dataset 519\n",
      "Dataset 819\n",
      "Dataset 969\n",
      "Dataset 669\n",
      "Dataset 369\n",
      "Dataset 1119\n",
      "Dataset 220\n",
      "Dataset 70\n",
      "Dataset 520\n",
      "Dataset 820\n",
      "Dataset 970\n",
      "Dataset 670\n",
      "Dataset 370\n",
      "Dataset 1120\n",
      "Dataset 221\n",
      "Dataset 71\n",
      "Dataset 521\n",
      "Dataset 821\n",
      "Dataset 971\n",
      "Dataset 671\n",
      "Dataset 371\n",
      "Dataset 1121\n",
      "Dataset 222\n",
      "Dataset 72\n",
      "Dataset 522\n",
      "Dataset 822\n",
      "Dataset 972\n",
      "Dataset 672\n",
      "Dataset 372\n",
      "Dataset 1122\n",
      "Dataset 223\n",
      "Dataset 73\n",
      "Dataset 523\n",
      "Dataset 823\n",
      "Dataset 973\n",
      "Dataset 673\n",
      "Dataset 373\n",
      "Dataset 1123\n",
      "Dataset 224\n",
      "Dataset 74\n",
      "Dataset 524\n",
      "Dataset 824\n",
      "Dataset 974\n",
      "Dataset 674\n",
      "Dataset 374\n",
      "Dataset 1124\n",
      "Dataset 225\n",
      "Dataset 75\n",
      "Dataset 525\n",
      "Dataset 825\n",
      "Dataset 975\n",
      "Dataset 675\n",
      "Dataset 375\n",
      "Dataset 1125\n",
      "Dataset 226\n",
      "Dataset 76\n",
      "Dataset 526\n",
      "Dataset 826\n",
      "Dataset 976\n",
      "Dataset 676\n",
      "Dataset 376\n",
      "Dataset 1126\n",
      "Dataset 227\n",
      "Dataset 77\n",
      "Dataset 527\n",
      "Dataset 827\n",
      "Dataset 977\n",
      "Dataset 677\n",
      "Dataset 377\n",
      "Dataset 1127\n",
      "Dataset 228\n",
      "Dataset 78\n",
      "Dataset 528\n",
      "Dataset 828\n",
      "Dataset 978\n",
      "Dataset 678\n",
      "Dataset 378\n",
      "Dataset 1128\n",
      "Dataset 229\n",
      "Dataset 79\n",
      "Dataset 829\n",
      "Dataset 529\n",
      "Dataset 979\n",
      "Dataset 679\n",
      "Dataset 379\n",
      "Dataset 1129\n",
      "Dataset 230\n",
      "Dataset 80\n",
      "Dataset 830\n",
      "Dataset 530\n",
      "Dataset 980\n",
      "Dataset 680\n",
      "Dataset 380\n",
      "Dataset 1130\n",
      "Dataset 231\n",
      "Dataset 81\n",
      "Dataset 831\n",
      "Dataset 531\n",
      "Dataset 981\n",
      "Dataset 681\n",
      "Dataset 381\n",
      "Dataset 1131\n",
      "Dataset 232\n",
      "Dataset 82\n",
      "Dataset 832\n",
      "Dataset 532\n",
      "Dataset 982\n",
      "Dataset 682\n",
      "Dataset 382\n",
      "Dataset 1132\n",
      "Dataset 233\n",
      "Dataset 83\n",
      "Dataset 833\n",
      "Dataset 533\n",
      "Dataset 983\n",
      "Dataset 683\n",
      "Dataset 383\n",
      "Dataset 1133\n",
      "Dataset 234\n",
      "Dataset 84\n",
      "Dataset 834\n",
      "Dataset 534\n",
      "Dataset 984\n",
      "Dataset 684\n",
      "Dataset 384\n",
      "Dataset 1134\n",
      "Dataset 235\n",
      "Dataset 85\n",
      "Dataset 835\n",
      "Dataset 535\n",
      "Dataset 985\n",
      "Dataset 685\n",
      "Dataset 385\n",
      "Dataset 1135\n",
      "Dataset 236\n",
      "Dataset 86\n",
      "Dataset 836\n",
      "Dataset 536\n",
      "Dataset 986\n",
      "Dataset 686\n",
      "Dataset 386\n",
      "Dataset 1136\n",
      "Dataset 237\n",
      "Dataset 87\n",
      "Dataset 837\n",
      "Dataset 537\n",
      "Dataset 987\n",
      "Dataset 687\n",
      "Dataset 387\n",
      "Dataset 1137\n",
      "Dataset 238\n",
      "Dataset 88\n",
      "Dataset 838\n",
      "Dataset 538\n",
      "Dataset 988\n",
      "Dataset 688\n",
      "Dataset 388\n",
      "Dataset 1138\n",
      "Dataset 239\n",
      "Dataset 89\n",
      "Dataset 839\n",
      "Dataset 539\n",
      "Dataset 989\n",
      "Dataset 689\n",
      "Dataset 389\n",
      "Dataset 1139\n",
      "Dataset 240\n",
      "Dataset 90\n",
      "Dataset 840\n",
      "Dataset 540\n",
      "Dataset 990\n",
      "Dataset 690\n",
      "Dataset 390\n",
      "Dataset 1140\n",
      "Dataset 241\n",
      "Dataset 91\n",
      "Dataset 841\n",
      "Dataset 541\n",
      "Dataset 991\n",
      "Dataset 691\n",
      "Dataset 391\n",
      "Dataset 1141\n",
      "Dataset 242\n",
      "Dataset 92\n",
      "Dataset 842\n",
      "Dataset 542\n",
      "Dataset 992\n",
      "Dataset 692\n",
      "Dataset 392\n",
      "Dataset 1142\n",
      "Dataset 243\n",
      "Dataset 93\n",
      "Dataset 843\n",
      "Dataset 543\n",
      "Dataset 993\n",
      "Dataset 693\n",
      "Dataset 393\n",
      "Dataset 1143\n",
      "Dataset 244\n",
      "Dataset 94\n",
      "Dataset 844\n",
      "Dataset 544\n",
      "Dataset 994\n",
      "Dataset 694\n",
      "Dataset 394\n",
      "Dataset 1144\n",
      "Dataset 245\n",
      "Dataset 95\n",
      "Dataset 845\n",
      "Dataset 545\n",
      "Dataset 995\n",
      "Dataset 695\n",
      "Dataset 395\n",
      "Dataset 1145\n",
      "Dataset 246\n",
      "Dataset 96\n",
      "Dataset 846\n",
      "Dataset 546\n",
      "Dataset 996\n",
      "Dataset 696\n",
      "Dataset 396\n",
      "Dataset 1146\n",
      "Dataset 247\n",
      "Dataset 97\n",
      "Dataset 847\n",
      "Dataset 547\n",
      "Dataset 997\n",
      "Dataset 697\n",
      "Dataset 397\n",
      "Dataset 1147\n",
      "Dataset 248\n",
      "Dataset 98\n",
      "Dataset 848\n",
      "Dataset 548\n",
      "Dataset 998\n",
      "Dataset 698\n",
      "Dataset 398\n",
      "Dataset 1148\n",
      "Dataset 249\n",
      "Dataset 99\n",
      "Dataset 849\n",
      "Dataset 549\n",
      "Dataset 999\n",
      "Dataset 699\n",
      "Dataset 399\n",
      "Dataset 1149\n",
      "Dataset 250\n",
      "Dataset 100\n",
      "Dataset 850\n",
      "Dataset 550\n",
      "Dataset 1000\n",
      "Dataset 700\n",
      "Dataset 400\n",
      "Dataset 1150\n",
      "Dataset 251\n",
      "Dataset 101\n",
      "Dataset 851\n",
      "Dataset 551\n",
      "Dataset 1001\n",
      "Dataset 701\n",
      "Dataset 401\n",
      "Dataset 1151\n",
      "Dataset 252\n",
      "Dataset 102\n",
      "Dataset 852\n",
      "Dataset 552\n",
      "Dataset 1002\n",
      "Dataset 702\n",
      "Dataset 402\n",
      "Dataset 1152\n",
      "Dataset 253\n",
      "Dataset 103\n",
      "Dataset 853\n",
      "Dataset 553\n",
      "Dataset 1003\n",
      "Dataset 703\n",
      "Dataset 403\n",
      "Dataset 1153\n",
      "Dataset 254\n",
      "Dataset 104\n",
      "Dataset 854\n",
      "Dataset 554\n",
      "Dataset 1004\n",
      "Dataset 704\n",
      "Dataset 404\n",
      "Dataset 1154\n",
      "Dataset 255\n",
      "Dataset 105\n",
      "Dataset 855\n",
      "Dataset 555\n",
      "Dataset 1005\n",
      "Dataset 705\n",
      "Dataset 405\n",
      "Dataset 1155\n",
      "Dataset 256\n",
      "Dataset 106\n",
      "Dataset 856\n",
      "Dataset 556\n",
      "Dataset 1006\n",
      "Dataset 706\n",
      "Dataset 406\n",
      "Dataset 1156\n",
      "Dataset 257\n",
      "Dataset 107\n",
      "Dataset 857\n",
      "Dataset 557\n",
      "Dataset 1007\n",
      "Dataset 707\n",
      "Dataset 407\n",
      "Dataset 1157\n",
      "Dataset 258\n",
      "Dataset 108\n",
      "Dataset 858\n",
      "Dataset 558\n",
      "Dataset 1008\n",
      "Dataset 708\n",
      "Dataset 408\n",
      "Dataset 1158\n",
      "Dataset 259\n",
      "Dataset 109\n",
      "Dataset 859\n",
      "Dataset 559\n",
      "Dataset 1009\n",
      "Dataset 709\n",
      "Dataset 409\n",
      "Dataset 1159\n",
      "Dataset 260\n",
      "Dataset 110\n",
      "Dataset 860\n",
      "Dataset 1010\n",
      "Dataset 560\n",
      "Dataset 710\n",
      "Dataset 410\n",
      "Dataset 1160\n",
      "Dataset 261\n",
      "Dataset 111\n",
      "Dataset 861\n",
      "Dataset 1011\n",
      "Dataset 561\n",
      "Dataset 711\n",
      "Dataset 411\n",
      "Dataset 1161\n",
      "Dataset 262\n",
      "Dataset 112\n",
      "Dataset 862\n",
      "Dataset 1012\n",
      "Dataset 562\n",
      "Dataset 712\n",
      "Dataset 412\n",
      "Dataset 1162\n",
      "Dataset 263\n",
      "Dataset 113\n",
      "Dataset 863\n",
      "Dataset 1013\n",
      "Dataset 563\n",
      "Dataset 713\n",
      "Dataset 413\n",
      "Dataset 1163\n",
      "Dataset 264\n",
      "Dataset 114\n",
      "Dataset 864\n",
      "Dataset 1014\n",
      "Dataset 564\n",
      "Dataset 714\n",
      "Dataset 414\n",
      "Dataset 1164\n",
      "Dataset 265\n",
      "Dataset 115\n",
      "Dataset 865\n",
      "Dataset 1015\n",
      "Dataset 565\n",
      "Dataset 715\n",
      "Dataset 415\n",
      "Dataset 1165\n",
      "Dataset 266\n",
      "Dataset 116\n",
      "Dataset 866\n",
      "Dataset 1016\n",
      "Dataset 566\n",
      "Dataset 716\n",
      "Dataset 416\n",
      "Dataset 1166\n",
      "Dataset 267\n",
      "Dataset 117\n",
      "Dataset 867\n",
      "Dataset 1017\n",
      "Dataset 567\n",
      "Dataset 717\n",
      "Dataset 417\n",
      "Dataset 1167\n",
      "Dataset 268\n",
      "Dataset 118\n",
      "Dataset 868\n",
      "Dataset 1018\n",
      "Dataset 568\n",
      "Dataset 718\n",
      "Dataset 418\n",
      "Dataset 1168\n",
      "Dataset 269\n",
      "Dataset 119\n",
      "Dataset 869\n",
      "Dataset 1019\n",
      "Dataset 569\n",
      "Dataset 719\n",
      "Dataset 419\n",
      "Dataset 1169\n",
      "Dataset 270\n",
      "Dataset 120\n",
      "Dataset 870\n",
      "Dataset 1020\n",
      "Dataset 570\n",
      "Dataset 720\n",
      "Dataset 420\n",
      "Dataset 1170\n",
      "Dataset 271\n",
      "Dataset 121\n",
      "Dataset 871\n",
      "Dataset 1021\n",
      "Dataset 571\n",
      "Dataset 721\n",
      "Dataset 421\n",
      "Dataset 1171\n",
      "Dataset 272\n",
      "Dataset 122\n",
      "Dataset 872\n",
      "Dataset 1022\n",
      "Dataset 572\n",
      "Dataset 722\n",
      "Dataset 1172\n",
      "Dataset 422\n",
      "Dataset 273\n",
      "Dataset 123\n",
      "Dataset 873\n",
      "Dataset 1023\n",
      "Dataset 573\n",
      "Dataset 723\n",
      "Dataset 423\n",
      "Dataset 1173\n",
      "Dataset 274\n",
      "Dataset 124\n",
      "Dataset 874\n",
      "Dataset 1024\n",
      "Dataset 574\n",
      "Dataset 724\n",
      "Dataset 424\n",
      "Dataset 1174\n",
      "Dataset 275\n",
      "Dataset 125\n",
      "Dataset 1025\n",
      "Dataset 875\n",
      "Dataset 575\n",
      "Dataset 725\n",
      "Dataset 425\n",
      "Dataset 1175\n",
      "Dataset 276\n",
      "Dataset 126\n",
      "Dataset 1026\n",
      "Dataset 876\n",
      "Dataset 576\n",
      "Dataset 726\n",
      "Dataset 1176\n",
      "Dataset 426\n",
      "Dataset 277\n",
      "Dataset 127\n",
      "Dataset 1027\n",
      "Dataset 877\n",
      "Dataset 577\n",
      "Dataset 727\n",
      "Dataset 1177\n",
      "Dataset 427\n",
      "Dataset 278\n",
      "Dataset 128\n",
      "Dataset 1028\n",
      "Dataset 878\n",
      "Dataset 578\n",
      "Dataset 728\n",
      "Dataset 428\n",
      "Dataset 1178\n",
      "Dataset 279\n",
      "Dataset 129\n",
      "Dataset 1029\n",
      "Dataset 879\n",
      "Dataset 579\n",
      "Dataset 729\n",
      "Dataset 1179\n",
      "Dataset 429\n",
      "Dataset 280\n",
      "Dataset 130\n",
      "Dataset 1030\n",
      "Dataset 880\n",
      "Dataset 580\n",
      "Dataset 730\n",
      "Dataset 1180\n",
      "Dataset 430\n",
      "Dataset 281\n",
      "Dataset 131\n",
      "Dataset 1031\n",
      "Dataset 881\n",
      "Dataset 581\n",
      "Dataset 731\n",
      "Dataset 1181\n",
      "Dataset 431\n",
      "Dataset 282\n",
      "Dataset 132\n",
      "Dataset 1032\n",
      "Dataset 882\n",
      "Dataset 582\n",
      "Dataset 732\n",
      "Dataset 1182\n",
      "Dataset 432\n",
      "Dataset 283\n",
      "Dataset 133\n",
      "Dataset 1033\n",
      "Dataset 883\n",
      "Dataset 583\n",
      "Dataset 733\n",
      "Dataset 1183\n",
      "Dataset 433\n",
      "Dataset 284\n",
      "Dataset 134\n",
      "Dataset 1034\n",
      "Dataset 884\n",
      "Dataset 584\n",
      "Dataset 734\n",
      "Dataset 1184\n",
      "Dataset 434\n",
      "Dataset 285\n",
      "Dataset 135\n",
      "Dataset 1035\n",
      "Dataset 885\n",
      "Dataset 585\n",
      "Dataset 735\n",
      "Dataset 1185\n",
      "Dataset 435\n",
      "Dataset 286\n",
      "Dataset 136\n",
      "Dataset 1036\n",
      "Dataset 886\n",
      "Dataset 586\n",
      "Dataset 736\n",
      "Dataset 1186\n",
      "Dataset 436\n",
      "Dataset 287\n",
      "Dataset 137\n",
      "Dataset 1037\n",
      "Dataset 887\n",
      "Dataset 587\n",
      "Dataset 737\n",
      "Dataset 1187\n",
      "Dataset 437\n",
      "Dataset 288\n",
      "Dataset 138\n",
      "Dataset 888\n",
      "Dataset 1038\n",
      "Dataset 588\n",
      "Dataset 738\n",
      "Dataset 1188\n",
      "Dataset 438\n",
      "Dataset 289\n",
      "Dataset 139\n",
      "Dataset 889\n",
      "Dataset 1039\n",
      "Dataset 589\n",
      "Dataset 739\n",
      "Dataset 1189\n",
      "Dataset 439\n",
      "Dataset 290\n",
      "Dataset 140\n",
      "Dataset 890\n",
      "Dataset 1040\n",
      "Dataset 590\n",
      "Dataset 740\n",
      "Dataset 1190\n",
      "Dataset 440\n",
      "Dataset 291\n",
      "Dataset 141\n",
      "Dataset 891\n",
      "Dataset 1041\n",
      "Dataset 591\n",
      "Dataset 741\n",
      "Dataset 1191\n",
      "Dataset 441\n",
      "Dataset 292\n",
      "Dataset 142\n",
      "Dataset 1042\n",
      "Dataset 892\n",
      "Dataset 592\n",
      "Dataset 742\n",
      "Dataset 1192\n",
      "Dataset 442\n",
      "Dataset 293\n",
      "Dataset 143\n",
      "Dataset 1043\n",
      "Dataset 893\n",
      "Dataset 593\n",
      "Dataset 743\n",
      "Dataset 1193\n",
      "Dataset 443\n",
      "Dataset 294\n",
      "Dataset 144\n",
      "Dataset 1044\n",
      "Dataset 894\n",
      "Dataset 594\n",
      "Dataset 744\n",
      "Dataset 1194\n",
      "Dataset 444\n",
      "Dataset 295\n",
      "Dataset 145\n",
      "Dataset 895\n",
      "Dataset 1045\n",
      "Dataset 595\n",
      "Dataset 745\n",
      "Dataset 1195\n",
      "Dataset 445\n",
      "Dataset 296\n",
      "Dataset 146\n",
      "Dataset 896\n",
      "Dataset 1046\n",
      "Dataset 596\n",
      "Dataset 746\n",
      "Dataset 1196\n",
      "Dataset 446\n",
      "Dataset 297\n",
      "Dataset 147\n",
      "Dataset 897\n",
      "Dataset 1047\n",
      "Dataset 597\n",
      "Dataset 747\n",
      "Dataset 1197\n",
      "Dataset 447\n",
      "Dataset 298\n",
      "Dataset 148\n",
      "Dataset 898\n",
      "Dataset 1048\n",
      "Dataset 598\n",
      "Dataset 748\n",
      "Dataset 1198\n",
      "Dataset 448\n",
      "Dataset 299\n",
      "Dataset 149\n",
      "Dataset 899\n",
      "Dataset 1049\n",
      "Dataset 599\n",
      "Dataset 749\n",
      "Dataset 1199\n",
      "Dataset 449\n",
      "Dataset 300\n",
      "Dataset 150\n",
      "Dataset 900\n",
      "Dataset 1050\n",
      "Dataset 600\n",
      "Dataset 750\n",
      "Dataset 1200\n",
      "Dataset 450\n",
      "parallel finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-211aed77d941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parallel finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrrr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_upload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-f71d8d508ef9>\u001b[0m in \u001b[0;36mmake_upload_file\u001b[0;34m(start_dataset, end_dataset, all_rules, df)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m241\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mpatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-f71d8d508ef9>\u001b[0m in \u001b[0;36mcheck_group\u001b[0;34m(patient, rule)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Grouping method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def parallel_execution():\n",
    "    pool=Pool(8)\n",
    "    params = []\n",
    "    for i in range(8):\n",
    "        #params.append((testing_data, i+1, (i+1), 1))\n",
    "        params.append((testing_data, (i*150)+1, (i+1)*150, 1))\n",
    "\n",
    "    r = pool.map(analysis, params)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return r\n",
    "\n",
    "# Calculate the execution time\n",
    "start_time = time.time()\n",
    "results = parallel_execution()\n",
    "print('parallel finished')\n",
    "rrr = make_upload_file(1, 1201, results, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = pandas.DataFrame([], columns=(['id'] + ['dataset_{}'.format(i) for i in range(1, 1201)]))\n",
    "ans['id'] = range(1, 241)\n",
    "output_file = 'result_test.csv'\n",
    "s_all = results.copy()\n",
    "for i in range(8):\n",
    "    ans = make_upload_file((i*150)+1, (i+1)*150, s_all[i], testing_data, ans)\n",
    "ans.to_csv(output_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>gp_effect_size</th>\n",
       "      <th>gp_num</th>\n",
       "      <th>gp_trt_effect</th>\n",
       "      <th>gp_p</th>\n",
       "      <th>gp_1_mean</th>\n",
       "      <th>gp_1_num</th>\n",
       "      <th>gp_0_mean</th>\n",
       "      <th>gn_trt_effect</th>\n",
       "      <th>gn_p</th>\n",
       "      <th>gn_1_mean</th>\n",
       "      <th>gn_1_num</th>\n",
       "      <th>gn_0_mean</th>\n",
       "      <th>trt_effect_1</th>\n",
       "      <th>p_1</th>\n",
       "      <th>trt_effect_0</th>\n",
       "      <th>p_0</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, [2], 0]</td>\n",
       "      <td>-1.221997</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1.566394</td>\n",
       "      <td>0.015757</td>\n",
       "      <td>6.354231</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.920625</td>\n",
       "      <td>-0.357587</td>\n",
       "      <td>0.031892</td>\n",
       "      <td>7.104216</td>\n",
       "      <td>148.0</td>\n",
       "      <td>7.461803</td>\n",
       "      <td>-0.749985</td>\n",
       "      <td>0.029171</td>\n",
       "      <td>0.458822</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rule  gp_effect_size  gp_num  gp_trt_effect      gp_p  gp_1_mean  \\\n",
       "0  [5, [2], 0]       -1.221997    21.0      -1.566394  0.015757   6.354231   \n",
       "\n",
       "   gp_1_num  gp_0_mean  gn_trt_effect      gn_p  gn_1_mean  gn_1_num  \\\n",
       "0      13.0   7.920625      -0.357587  0.031892   7.104216     148.0   \n",
       "\n",
       "   gn_0_mean  trt_effect_1       p_1  trt_effect_0       p_0  score  \n",
       "0   7.461803     -0.749985  0.029171      0.458822  0.455341    0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd = pandas.read_pickle('score/Dataset1_score.p')\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59.00\n",
       "1      30.08\n",
       "2      26.92\n",
       "3      69.50\n",
       "4      52.35\n",
       "5      39.98\n",
       "6      50.11\n",
       "7       8.43\n",
       "8      44.69\n",
       "9      19.01\n",
       "10     55.00\n",
       "11     57.63\n",
       "12     20.87\n",
       "13     51.29\n",
       "14     34.43\n",
       "15     27.85\n",
       "16     96.75\n",
       "17      6.92\n",
       "18      9.64\n",
       "19      7.62\n",
       "20     20.04\n",
       "21     36.76\n",
       "22     83.63\n",
       "23      3.17\n",
       "24     71.13\n",
       "25     64.02\n",
       "26     38.70\n",
       "27     63.57\n",
       "28     28.11\n",
       "29     83.28\n",
       "       ...  \n",
       "930     9.95\n",
       "931    11.95\n",
       "932    72.07\n",
       "933    39.30\n",
       "934    24.83\n",
       "935    42.65\n",
       "936    57.06\n",
       "937    54.08\n",
       "938    47.64\n",
       "939    44.71\n",
       "940    93.89\n",
       "941    39.69\n",
       "942    65.98\n",
       "943    33.60\n",
       "944    94.54\n",
       "945    37.98\n",
       "946    88.16\n",
       "947    33.08\n",
       "948    56.42\n",
       "949    96.82\n",
       "950    26.50\n",
       "951    80.22\n",
       "952    46.75\n",
       "953    19.11\n",
       "954    48.60\n",
       "955    54.44\n",
       "956    72.43\n",
       "957    89.46\n",
       "958    96.94\n",
       "959    76.49\n",
       "Name: x21, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
